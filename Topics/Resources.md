









*2023-01-07*

#### [Î¼ KG: A Library for Multi-source Knowledge Graph Embeddings and Applications](https://link.springer.com/chapter/10.1007/978-3-031-19433-7_35)

*Xindi Luo, Zequn Sun, Wei Hu*

*ISWC 2022*

This resource paper provides an open-source Python library consisting of 26 popular knowledge graph embedding models and 16 benchmark datasets. 


*2022-12-22*

#### [WDV: A Broad Data Verbalisation Dataset Built from Wikidata](https://link.springer.com/chapter/10.1007/978-3-031-19433-7_32)

*Gabriel Amaral, Odinaldo Rodrigues, Elena Simperl*

*ISWC 2023*

This resource paper proposes a dataset consists of over 7.6k Wikidata entries and their verbalized textual version. The dataset is made up from crowdsourcing annotations. Each entry contains textual descriptions of the subject, predicate and object in Wikidata, respectively.  


*2022-11-28*

#### [HybridQA: A Dataset of Multi-Hop Question Answering over Tabular and Textual Data](https://doi.org/10.18653/v1/2020.findings-emnlp.91)

*Wenhu Chen, Hanwen Zha, Zhiyu Chen, Wenhan Xiong, Hong Wang, William Yang Wang*

*EMNLP Findings 2020*

This paper proposes a question answering dataset containing both a Wikipedia table and a set of passages as resources. It begins with selecting Wikipedia tables which have hyperlinked cells. Then it retrieves the Wikipedia pages of each cell and collects the first sentences as supporting textual data. The questions are collected using AMT and post-processed to avoid bias. 


*2022-11-27*

#### [FinQA: A Dataset of Numerical Reasoning over Financial Data](https://doi.org/10.18653/v1/2021.emnlp-main.300)

*Zhiyu Chen, Wenhu Chen, Charese Smiley, Sameena Shah, Iana Borova, Dylan Langdon, Reema Moussa, Matt Beane, Ting-Hao Huang, Bryan R. Routledge, William Yang Wang*

*EMNLP 2021*

This paper proposes a dataset named FinQA containing question-answer pairs with annotated reasoning explanations based on financial reports. By implementing existing QA methods as baseline, the experimental results suggest existing pre-trained language models still fall far short than humans in acquiring finance knowledge and conducting multi-step numerical reasoning. 
