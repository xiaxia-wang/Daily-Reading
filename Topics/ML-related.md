



*2023-08-17*

#### [Is Reinforcement Learning (Not) for Natural Language Processing: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization](https://openreview.net/pdf?id=8aHzds2uUyB)

*Rajkumar Ramamurthy, Prithviraj Ammanabrolu, Kianté Brantley, Jack Hessel, Rafet Sifa, Christian Bauckhage, Hannaneh Hajishirzi, Yejin Choi*

*ICLR 2023*

This paper proposes to solve NLP tasks in a reinforcement learning view. It uses an open-sourced library for optimizing language generators with RL, and presents a benchmark consisting of 6 natural language generation tasks with reward functions from human preference. Besides, it also provides an RL algorithm named NLPO that learns to effectively reduce the combinatorial action space in language generation.


*2023-08-14*

#### [Sparse Mixture-of-Experts are Domain Generalizable Learners](https://openreview.net/pdf?id=RecZ9nB9Q4)

*Bo Li, Yifei Shen, Jingkang Yang, Yezhen Wang, Jiawei Ren, Tong Che, Jun Zhang, Ziwei Liu*

*ICLR 2023*

To address the problem of domain generalization, this paper proposes a model built upon vision transformers, in which the network's robustness to distribution shifts is characterized by the architecture's alignment with the correlations in the dataset.


*2023-08-12*

#### [Learning with Logical Constraints but without Shortcut Satisfaction](https://openreview.net/pdf?id=M2unceRvqhh)

*Zenan Li, Zehua Liu, Yuan Yao, Jingwei Xu, Taolue Chen, Xiaoxing Ma, Jian Lü*

*ICLR 2023*

Noticing that existing methods with loss function including logical constraints may be bypassed with shortcuts thus not fully exploiting intrinsic knowledge, this paper designs a new loss function for logical constraints. It introduces an additional random variable for the logical constraint indicating its satisfaction degree, and formulates it as a distributional loss which is compatible with the neural network’s original training loss under a variational framework.


*2023-08-11*

#### [A Survey on the Explainability of Supervised Machine Learning](https://jair.org/index.php/jair/article/view/12228)

*Nadia Burkart, Marco F. Huber*

*JAIR 2021*

This paper discusses the essential definitions, an overview of different principles and methodologies of explainable supervised machine learning.


*2023-08-07*

#### [What learning algorithm is in-context learning? Investigations with linear models](https://openreview.net/pdf?id=0g0X4H8yN4I)

*Ekin Akyürek, Dale Schuurmans, Jacob Andreas, Tengyu Ma, Denny Zhou*

*ICLR 2023*

This paper investigates the hypothesis that transformer-based in-context learners implement standard learning algorithms implicitly by encoding smaller models in their activations, and updating these implicit models as new examples appear in the context. The hypothesis is evaluated with the problem of linear regression, and demonstrated with several source of evidence.


*2023-08-05*

#### [Encoding Recurrence into Transformers](https://openreview.net/pdf?id=7YfHla7IxBJ)

*Feiqing Huang, Kexin Lu, Yuxi Cai, Zhen Qin, Yanwen Fang, Guangjian Tian, Guodong Li*

*ICLR 2023*

This paper proposes to equivalently replace a RNN layer with a set of simple RNNs, and further by a multi-head self-attention block. It further proposes a new module named Self-Attention with Recurrence, which can incorporate the recurrent dynamics into a transformer.


*2023-07-03*

#### [Normalizing Flow-based Neural Process for Few-Shot Knowledge Graph Completion](https://arxiv.org/abs/2304.08183)

*Linhao Luo, Reza Haffari, Yuan Fang Li, Shirui Pan*

*SIGIR 2023*

Neural Processes (NPs) combine the stochastic process and neural networks to define a distribution over prediction functions with limited observed data. Normalizing flows (NFs) [36] employ a sequence of bijective mapping functions to transform a simple distribution into a complex target distribution. This paper applies the NPs and normalized flows in an encoder-decoder model for KGC.


*2023-05-21*

#### [KGA: A General Machine Unlearning Framework Based on Knowledge Gap Alignment](https://arxiv.org/pdf/2305.06535.pdf)

*Lingzhi Wang, Tong Chen, Wei Yuan, Xingshan Zeng, Kam-Fai Wong, Hongzhi Yin*

*ACL 2023*

Machine unlearning refers to the ability of the learned model to forget information about specific training data as if they never existed in the training set. This paper follows the idea of approximate unlearning, whose goal is to forget the data to be forgotten while maintaining the performance. To achieve this, it optimizes the model to have similar behaviors on the data to be forgotten as unseen data, while maintaining the performance on the rest of data.
