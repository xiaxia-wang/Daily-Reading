




*2023-10-30*

#### [Incremental Tabular Learning on Heterogeneous Feature Space](https://dl.acm.org/doi/pdf/10.1145/3588698)

*Hanmo Liu, Shimin Di, Lei Chen*

*SIGMOD 2023*

Existing methods for incremental tabular learning usually assume that the new-coming datasets are from the same feature space as the old ones, i.e., homogeneous feature space, while in practice this is not always the case. To address this problem, this paper proposes an approach for incremental tabular learning in heterogeneous feature space. Specifically, it proposes different feature extractors for heterogeneous feature sets, as well as a measurement for the discrimination of these extractors. The overall loss function includes cross-entropy, regularization, and discriminative losses.


*2023-10-28*

#### [XTab: Cross-table Pretraining for Tabular Transformers](https://proceedings.mlr.press/v202/zhu23k.html)

*Bingzhao Zhu, Xingjian Shi, Nick Erickson, Mu Li, George Karypis, Mahsa Shoaran*

*ICML 2023*

This paper proposes a cross-table pretrained transformer model which can handle tables from different domains and of various formats. Specifically, the proposed model architecture consists of a shared backbone transformer block, and data-specific featurizers and projection heads for different (pretraining) downstream tasks.

